{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rural-copying",
      "metadata": {
        "id": "rural-copying"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fantastic-capital",
      "metadata": {
        "id": "fantastic-capital"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "perceived-contract",
      "metadata": {
        "id": "perceived-contract"
      },
      "outputs": [],
      "source": [
        "DIRECTORY = r'C:\\Users\\Kaustubh\\Desktop\\Projects'\n",
        "\n",
        "CATEGORIES = ['GAN', 'Nongan']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hybrid-bikini",
      "metadata": {
        "id": "hybrid-bikini"
      },
      "outputs": [],
      "source": [
        "image_size=180\n",
        "data1 = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DIRECTORY, category)\n",
        "    label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        img_path = os.path.join(path, img)\n",
        "        arr = cv2.imread(img_path)\n",
        "        new_arr = cv2.resize(arr, (image_size, image_size))\n",
        "        data1.append([new_arr, label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moral-metropolitan",
      "metadata": {
        "id": "moral-metropolitan",
        "outputId": "0fd17c65-9a80-42c3-acaa-257101aa62b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "empty-twins",
      "metadata": {
        "id": "empty-twins"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unlikely-ground",
      "metadata": {
        "id": "unlikely-ground"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for features,labels in data1:\n",
        "    x.append(features)\n",
        "    y.append(labels)\n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "grave-sugar",
      "metadata": {
        "id": "grave-sugar"
      },
      "outputs": [],
      "source": [
        "x=x/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stuffed-genealogy",
      "metadata": {
        "id": "stuffed-genealogy",
        "outputId": "8c354358-5f29-4ce9-b717-a96ad524e7f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "authentic-virginia",
      "metadata": {
        "id": "authentic-virginia"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dietary-cycling",
      "metadata": {
        "id": "dietary-cycling"
      },
      "outputs": [],
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #x.reshape(len(input_train), input_shape[0], input_shape[1], input_shape[2])\n",
        "    tf.keras.layers.Dense(128,input_shape=x.shape[1:],activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)])#output(training Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acute-mount",
      "metadata": {
        "id": "acute-mount"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valued-steam",
      "metadata": {
        "id": "valued-steam",
        "outputId": "543ed8ce-33af-4d73-d20e-41f5ad2fe2a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "preceding-laptop",
      "metadata": {
        "id": "preceding-laptop",
        "outputId": "bc780386-1d8d-4a4e-f81e-b066f40e925b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.5796 - accuracy: 0.3952 - val_loss: 0.8897 - val_accuracy: 0.5000\n",
            "Epoch 2/7\n",
            "6/6 [==============================] - 6s 948ms/step - loss: 0.7451 - accuracy: 0.5389 - val_loss: 0.8585 - val_accuracy: 0.5000\n",
            "Epoch 3/7\n",
            "6/6 [==============================] - 6s 986ms/step - loss: 0.7533 - accuracy: 0.5749 - val_loss: 0.6178 - val_accuracy: 0.6905\n",
            "Epoch 4/7\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.6697 - accuracy: 0.5749 - val_loss: 0.6271 - val_accuracy: 0.8095\n",
            "Epoch 5/7\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.6276 - accuracy: 0.5868 - val_loss: 0.5428 - val_accuracy: 0.9762\n",
            "Epoch 6/7\n",
            "6/6 [==============================] - 6s 986ms/step - loss: 0.4825 - accuracy: 0.9701 - val_loss: 0.3905 - val_accuracy: 1.0000\n",
            "Epoch 7/7\n",
            "6/6 [==============================] - 6s 964ms/step - loss: 0.3326 - accuracy: 0.9641 - val_loss: 0.2152 - val_accuracy: 0.9762\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x259d641a2e0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x,y,epochs=7,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encouraging-friend",
      "metadata": {
        "id": "encouraging-friend",
        "outputId": "1e67a99f-ab34-4122-b28d-89c6e94fd3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 178, 178, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 89, 89, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 87, 87, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 41, 41, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               3276928   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,353,866\n",
            "Trainable params: 3,353,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "changed-assurance",
      "metadata": {
        "id": "changed-assurance",
        "outputId": "44b56065-b9f7-467d-ba0d-2ae2e532ff11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1617090890.1596408.png', '1617090890.665641.png', '1617090891.153641.png', 'out82.png', 'out83.png', 'out84.png']\n"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "predict_dir_path=r'C:\\Users\\Kaustubh\\Desktop\\Projects'\n",
        "onlyfiles = [f for f in listdir(predict_dir_path) if isfile(join(predict_dir_path, f))]\n",
        "print(onlyfiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "authorized-italy",
      "metadata": {
        "id": "authorized-italy",
        "outputId": "d437970a-3c83-4a2f-aa3c-888ca1162e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1617090890.1596408.png: GAN\n",
            "1617090890.665641.png: GAN\n",
            "1617090891.153641.png: GAN\n",
            "out82.png: NON-GAN\n",
            "out83.png: GAN\n",
            "out84.png: NON-GAN\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(predict_dir_path+file, target_size=(image_size, image_size))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size=10)\n",
        "    #classes = classes[0][0]\n",
        "\n",
        "    if classes == 0:\n",
        "        print(file + \": \" + 'GAN')\n",
        "        #COVID += 1\n",
        "    else:\n",
        "        print(file + \": \" + 'NON-GAN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "appointed-karma",
      "metadata": {
        "id": "appointed-karma"
      },
      "outputs": [],
      "source": [
        "model.save(\"new_model.hp5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fiscal-passing",
      "metadata": {
        "id": "fiscal-passing"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}